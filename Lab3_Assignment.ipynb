{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd, numpy as np, matplotlib, matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_mental_health(df):\n",
    "    one_hot = ['Gender', 'Country', 'state', 'self_employed', \n",
    "               'family_history', 'work_interfere', 'no_employees',\n",
    "               'remote_work', 'tech_company', 'benefits', 'care_options',\n",
    "               'wellness_program', 'seek_help', 'anonymity', 'leave',\n",
    "               'mental_health_consequence', 'phys_health_consequence', 'coworkers',\n",
    "               'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "               'mental_vs_physical', 'obs_consequence']\n",
    "    numeric = ['Age']\n",
    "    timestamp_to_numeric = ['Timestamp']\n",
    "\n",
    "    data = df.loc[:,'treatment']\n",
    "    data = data.str.replace('No', '1').str.replace('Yes', '0').astype(float)\n",
    "\n",
    "    for col in one_hot:\n",
    "        new_data = df.loc[:,col]\n",
    "        if new_data.unique().shape[0] < 2:\n",
    "            #Throw away column if constant\n",
    "            continue\n",
    "        elif new_data.unique().shape[0] == 2:\n",
    "            #If two values, create binary representation\n",
    "            new_data = (new_data == new_data.unique()[0]).astype(float)\n",
    "        else:\n",
    "            #If more than two unique values, create one hot representation\n",
    "            new_data = pd.get_dummies(new_data)\n",
    "        data = pd.concat((data, new_data), 1)\n",
    "\n",
    "    for col in numeric:\n",
    "        new_data = df.loc[:,col]\n",
    "        new_data = new_data.astype(float)\n",
    "        data = pd.concat((data, new_data), 1)\n",
    "\n",
    "    for col in timestamp_to_numeric:\n",
    "        new_data = df.loc[:,col]\n",
    "        new_data = pd.to_numeric(pd.to_datetime(new_data))\n",
    "        data = pd.concat((data, new_data), 1)\n",
    "\n",
    "    #Convert data pandas to numpy\n",
    "    data = data.as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_mnist():\n",
    "    import torchvision\n",
    "    data = torchvision.datasets.MNIST(root='.', download=True)\n",
    "    train_data = data.train_data.numpy().reshape(60000, -1)\n",
    "    train_labels = data.train_labels.numpy().reshape(60000, -1)\n",
    "\n",
    "    data_test = torchvision.datasets.MNIST(root='.', download=True, train=False)\n",
    "    test_data = data_test.test_data.numpy().reshape(10000, -1)\n",
    "    test_labels = data_test.test_labels.numpy().reshape(10000, -1)\n",
    "\n",
    "    data = np.concatenate([train_data, test_data], axis=0)\n",
    "    labels = np.concatenate([train_labels, test_labels], axis=0)\n",
    "    labels = np.isin(labels,[1, 2, 4, 7, 9]).astype(float)\n",
    "    data = np.concatenate([labels, data], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:# dataset is mental health\n",
    "    df = pd.read_csv('mental_health_survey.csv')\n",
    "    data = process_mental_health(df)\n",
    "    dataset = 'health'\n",
    "else:#Choose MNIST\n",
    "    data = process_mnist()\n",
    "    dataset = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check the final shape of our in-use dataset\n",
    "print('data shape', data.shape)\n",
    "\n",
    "#Feature shapes\n",
    "num_rows, num_features = data.shape[0], data.shape[1]-1\n",
    "\n",
    "#Select Training rows\n",
    "np.random.seed(0)\n",
    "trn_rows = np.sort(np.random.choice(num_rows, size = int(num_rows * .7), replace = False))\n",
    "\n",
    "#Select Validation rows\n",
    "val_rows = np.setdiff1d(np.arange(num_rows), trn_rows)\n",
    "\n",
    "#Split dataset\n",
    "trn_data, val_data = data[trn_rows,1:], data[val_rows,1:]\n",
    "trn_Y, val_Y = data[trn_rows,0], data[val_rows,0]\n",
    "\n",
    "#already normalized when appropriate\n",
    "#Normalize training and validation based on training data\n",
    "data_mean, data_std = trn_data.mean(0), trn_data.std(0) + 1e-8\n",
    "\n",
    "def normalize_data(data, data_mean, data_std):\n",
    "    normalized = (data - np.expand_dims(data_mean,0)) / np.expand_dims(data_std,0)\n",
    "    normalized = np.clip(normalized, -5, 5)\n",
    "    return normalized\n",
    "\n",
    "trn_normalized = normalize_data(trn_data, data_mean, data_std)\n",
    "val_normalized = normalize_data(val_data, data_mean, data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code to cleanly swap between Pytorch and Numpy.\n",
    "# Makes PyTorch much more user friendly, but not widely used. \n",
    "# Base code from Andy Gan (Github BarclayII) with some minor additions\n",
    "\n",
    "#Main adjustable flag. Enables or Disable GPU optimizations\n",
    "USE_CUDA = 1\n",
    "\n",
    "def cuda(obj):\n",
    "    if USE_CUDA:\n",
    "        if isinstance(obj, tuple):\n",
    "            return tuple(cuda(o) for o in obj)\n",
    "        elif isinstance(obj, list):\n",
    "            return list(cuda(o) for o in obj)\n",
    "        elif hasattr(obj, 'cuda'):\n",
    "            return obj.cuda()\n",
    "    return obj\n",
    "\n",
    "def tovar(*arrs, **kwargs):\n",
    "    tensors = [(torch.from_numpy(a) if isinstance(a, np.ndarray) else a) for a in arrs]\n",
    "    vars_ = [torch.autograd.Variable(t, **kwargs) for t in tensors]\n",
    "    if USE_CUDA:\n",
    "        vars_ = [v.cuda() for v in vars_]\n",
    "    return vars_[0] if len(vars_) == 1 else vars_\n",
    "\n",
    "\n",
    "def tonumpy(*vars_):\n",
    "    arrs = [(v.data.cpu().numpy() if isinstance(v, torch.autograd.Variable) else\n",
    "             v.cpu().numpy() if torch.is_tensor(v) else v) for v in vars_]\n",
    "    return arrs[0] if len(arrs) == 1 else arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the network in pytorch\n",
    "\n",
    "def init_weights(module):\n",
    "    #Optional: Initialize weights using Xavier Initialization \n",
    "    for name, param in module.named_parameters():\n",
    "        if name.find('weight') != -1:\n",
    "            if len(param.size()) == 1:\n",
    "                init.uniform(param.data, 1)\n",
    "            else:\n",
    "                init.xavier_uniform(param.data)\n",
    "        elif name.find('bias') != -1:\n",
    "            init.constant(param.data, 0)\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    #Identity Module\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,num_inputs, hidden_layers, output_fcn = None, lr = 1e-3, polynomial_features = False):\n",
    "        #num_inputs is the number of input feature\n",
    "        #Hidden layers is a list of hidden layer sizes)\n",
    "        #output_fcn should be either 'linear' or 'logistic'. Only Logistic is required\n",
    "        nn.Module.__init__(self)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.output_type = output_fcn\n",
    "        \n",
    "        prev_out_size = num_inputs\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        #TODO: Create and initialize network layers\n",
    "        #1- Network structure should contain hidden layers according to the list hidden_layers,\n",
    "        #2- If polynomial_features, expect the forward function to start \n",
    "        #   with degree two polynomail feature extraction before the first hidden layer\n",
    "\n",
    "        self.trn_losses = []\n",
    "        self.val_losses = []\n",
    "        self.trn_accs = []\n",
    "        self.val_accs = []\n",
    "        self.fscores = []\n",
    "        self.polynomial_features = polynomial_features\n",
    "        \n",
    "        #TODO: Set output function and loss function: self.output_fcn, self.loss_fcn\n",
    "        #      These should depend on the input variable output_fcn, or just choose one set of functions\n",
    "        \n",
    "        self.optimizer = torch.optim.RMSprop(self.parameters(), lr = lr, weight_decay = 1e-3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x is training data of shape [batch_size, num_inputs]\n",
    "        \n",
    "        #Convert numpy to variable\n",
    "        x = tovar(x).float()\n",
    "        \n",
    "        #Optional: First perform polynomial feature expansion\n",
    "        if self.polynomial_features:\n",
    "            rows, cols = x.size()\n",
    "            x_left = x.view((rows, cols, 1))\n",
    "            x_right = x.view((rows, 1, cols))\n",
    "            x = x_left.bmm(x_right).view((rows, cols*cols))\n",
    "        \n",
    "        #TODO: Project data through self.hidden_layers\n",
    "        #      Each followed by a nn.LeakyReLU activation function\n",
    "        \n",
    "        #TODO: End with projecting data through self.output_layer and self.output_fcn\n",
    "        \n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoff = .5\n",
    "def num_accurate(y_pred, y):\n",
    "    high = ((y_pred > cutoff) * (y == 1)).sum()\n",
    "    low = ((y_pred < cutoff) * (y == 0)).sum()\n",
    "    return high + low\n",
    "\n",
    "def confusion_matrix(y_pred, y):\n",
    "    TP = ((y_pred > cutoff) * (y == 1)).sum()\n",
    "    TN = ((y_pred < cutoff) * (y == 0)).sum()\n",
    "    FP = ((y_pred > cutoff) * (y == 0)).sum()\n",
    "    FN = ((y_pred < cutoff) * (y == 1)).sum()\n",
    "    confusion_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "    return confusion_matrix\n",
    "\n",
    "def F1_score(y_pred, y):\n",
    "    TP = ((y_pred > cutoff) * (y == 1)).sum()\n",
    "    TN = ((y_pred < cutoff) * (y == 0)).sum()\n",
    "    FP = ((y_pred > cutoff) * (y == 0)).sum()\n",
    "    FN = ((y_pred < cutoff) * (y == 1)).sum()\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    return np.sqrt(precision * recall)\n",
    "\n",
    "def train(epochs = 30, verbosity = 0, val_freq = 1):\n",
    "    num_epochs = epochs\n",
    "    if dataset == 'health':\n",
    "        bs = 32\n",
    "    if dataset == 'mnist':\n",
    "        bs = 256\n",
    "    rows_trn = len(trn_Y)\n",
    "    batches_per_epoch = rows_trn // bs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Optimize Model on mini batches\n",
    "        trn_loss = []\n",
    "        trn_acc = [0,0]\n",
    "        order = np.arange(rows_trn)\n",
    "        np.random.shuffle(order)\n",
    "        for itr in range(batches_per_epoch):\n",
    "            rows = order[itr*bs:(itr+1)*bs]\n",
    "            if itr+1 == batches_per_epoch:\n",
    "                rows = order[itr*bs:]\n",
    "            x, y = trn_normalized[rows,:], trn_Y[rows]\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            \n",
    "            loss = model.loss_fcn(y_pred, tovar(y).float())\n",
    "\n",
    "            # Before the backward pass, use the optimizer object to zero all of the \n",
    "            # gradients for the variables it will update (which are the learnable weights of the model)\n",
    "            model.optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its parameters\n",
    "            model.optimizer.step()\n",
    "            trn_loss.append(tonumpy(loss.data[0]))\n",
    "            y_pred_numpy = tonumpy(y_pred.data.float()).reshape(-1)\n",
    "            trn_acc[0] += num_accurate(y_pred_numpy, y)\n",
    "            trn_acc[1] += len(rows)\n",
    "        if epoch % val_freq == 0:\n",
    "            #Evaluate Performance on on validation set\n",
    "            trn_loss = np.mean(trn_loss)\n",
    "            model.trn_losses.append(trn_loss)\n",
    "            y_pred = model(val_normalized)\n",
    "            val_loss = model.loss_fcn(y_pred, tovar(val_Y).float()).data[0]\n",
    "            y_pred_numpy = tonumpy(y_pred.data.float()).reshape(-1)\n",
    "            val_acc = num_accurate(y_pred_numpy, val_Y) / len(val_Y)\n",
    "            trn_acc = trn_acc[0] / trn_acc[1]\n",
    "            if verbosity > 0 and epoch == num_epochs - 1:\n",
    "                print('confusion matrix')\n",
    "                print(confusion_matrix(y_pred_numpy, val_Y))\n",
    "            if verbosity > 1:\n",
    "                print( 'epoch:', epoch)\n",
    "                print('train loss: ',trn_loss, 'train acc', trn_acc)\n",
    "                print('val loss: ',val_loss, 'val acc', val_acc)\n",
    "            fscore = F1_score(y_pred_numpy, val_Y)\n",
    "            trn_loss = []\n",
    "            model.val_losses.append(val_loss)\n",
    "            model.val_accs.append(val_acc)\n",
    "            model.trn_accs.append(trn_acc)\n",
    "            model.fscores.append(fscore)\n",
    "def visualize(verbosity = 0):\n",
    "    #Visualize performance of training and validation throughout training\n",
    "    print('Best Loss:', min(model.val_losses))\n",
    "    print('Best Acc:', max(model.val_accs))\n",
    "    print('Best F score:', max(model.fscores))\n",
    "    plt.close()     \n",
    "    if verbosity > 0:\n",
    "        plt.plot(model.trn_losses, label='train loss')\n",
    "        plt.plot(model.val_losses, label='val loss')\n",
    "        plt.legend()\n",
    "        plt.title('losses')\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "    plt.plot(model.trn_accs, label='train acc')\n",
    "    plt.plot(model.val_accs, label='val acc')\n",
    "    plt.legend()\n",
    "    plt.title('accuracies')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(model.fscores, label='val f score')\n",
    "    plt.legend()\n",
    "    plt.title('F scores')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "verb = 0\n",
    "if dataset == 'health':\n",
    "    hidden_width = 1000\n",
    "if dataset == 'mnist':\n",
    "    hidden_width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = cuda(Model(num_features, hidden_layers = [], output_fcn = 'logistic'))\n",
    "train(epochs = num_epochs, verbosity = verb)\n",
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if dataset == 'health':\n",
    "    model = cuda(Model(num_features, hidden_layers = [], output_fcn = 'logistic', polynomial_features = True))\n",
    "    train(epochs = num_epochs, verbosity = verb)\n",
    "    visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = cuda(Model(num_features, hidden_layers = [hidden_width], output_fcn = 'logistic'))\n",
    "train(epochs = num_epochs, verbosity = verb)\n",
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = cuda(Model(num_features, hidden_layers = [hidden_width, hidden_width], output_fcn = 'logistic'))\n",
    "train(epochs = num_epochs, verbosity = verb)\n",
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
